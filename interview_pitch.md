## 30‑Second Interview Pitch

I built an end‑to‑end **PySpark** project on a retail purchases dataset to demonstrate practical big‑data skills. 
Starting with raw CSV, I treated zeros as missing, did median imputation, and created a clean DataFrame for analysis and modeling. 
I ran EDA with summary stats and plots, executed a Spark SQL filter query, and trained three MLlib models: Decision Tree, Logistic Regression, and Linear Regression. 
The repo is reproducible, with checkpoints, generated figures, saved metrics, a Makefile, and a Dockerfile so anyone can run it quickly. 
It shows I can design a small but complete data pipeline, reason about data quality, and explain model results clearly.
